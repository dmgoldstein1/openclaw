// Generated by Copilot (GPT-5.3-Codex): Verifies LM Studio implicit provider discovery from OpenAI-compatible /v1/models.
import { mkdtempSync } from "node:fs";
import { tmpdir } from "node:os";
import { join } from "node:path";
import { afterEach, describe, expect, it, vi } from "vitest";
import { resolveImplicitProviders } from "./models-config.providers.js";

afterEach(() => {
  vi.unstubAllEnvs();
  vi.unstubAllGlobals();
});

describe("LM Studio implicit provider", () => {
  it("discovers models from OPENAI_API_BASE /v1/models", async () => {
    const agentDir = mkdtempSync(join(tmpdir(), "openclaw-test-"));
    vi.stubEnv("VITEST", "");
    vi.stubEnv("NODE_ENV", "development");
    vi.stubEnv("OPENAI_API_BASE", "http://host.docker.internal:1234/v1");
    vi.stubEnv("OPENAI_API_KEY", "lmstudio-key");

    const fetchMock = vi.fn().mockResolvedValue({
      ok: true,
      json: async () => ({
        data: [{ id: "openai/gpt-oss-20b" }, { id: "qwen/qwen3-coder-30b" }],
      }),
    });
    vi.stubGlobal("fetch", fetchMock);

    const providers = await resolveImplicitProviders({ agentDir });
    const lmstudio = providers?.lmstudio;

    expect(lmstudio).toBeDefined();
    expect(lmstudio?.api).toBe("openai-completions");
    expect(lmstudio?.baseUrl).toBe("http://host.docker.internal:1234/v1");
    expect(lmstudio?.apiKey).toBe("OPENAI_API_KEY");
    expect(lmstudio?.models?.map((model) => model.id)).toEqual([
      "openai/gpt-oss-20b",
      "qwen/qwen3-coder-30b",
    ]);
  });

  it("normalizes endpoint to /v1/models when base URL has no /v1 suffix", async () => {
    const agentDir = mkdtempSync(join(tmpdir(), "openclaw-test-"));
    vi.stubEnv("VITEST", "");
    vi.stubEnv("NODE_ENV", "development");
    vi.stubEnv("OPENAI_API_BASE", "http://host.docker.internal:1234");

    const fetchMock = vi.fn().mockResolvedValue({
      ok: true,
      json: async () => ({ data: [{ id: "openai/gpt-oss-20b" }] }),
    });
    vi.stubGlobal("fetch", fetchMock);

    await resolveImplicitProviders({ agentDir });

    expect(
      fetchMock.mock.calls.some((call) => call[0] === "http://host.docker.internal:1234/v1/models"),
    ).toBe(true);
  });

  it("uses explicit lmstudio base URL when provided", async () => {
    const agentDir = mkdtempSync(join(tmpdir(), "openclaw-test-"));
    vi.stubEnv("VITEST", "");
    vi.stubEnv("NODE_ENV", "development");

    const fetchMock = vi.fn().mockResolvedValue({
      ok: true,
      json: async () => ({ data: [{ id: "minimax-m2.1-gs32" }] }),
    });
    vi.stubGlobal("fetch", fetchMock);

    const providers = await resolveImplicitProviders({
      agentDir,
      explicitProviders: {
        lmstudio: {
          baseUrl: "http://127.0.0.1:1234/v1",
          api: "openai-completions",
          models: [],
        },
      },
    });

    expect(providers?.lmstudio?.baseUrl).toBe("http://127.0.0.1:1234/v1");
    expect(providers?.lmstudio?.models?.map((model) => model.id)).toEqual(["minimax-m2.1-gs32"]);
  });
});
